{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from collections import deque\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "PREDICTION_WINDOW_SIZE = 5\n",
    "OBSERVATIONS_FOLDER = \"observations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    IDLE = 0\n",
    "    PICK = 1\n",
    "    PLACE = 2\n",
    "    SCREW_WRENCH = 3\n",
    "\n",
    "OBJECT_NAMES = {\n",
    "    0: \"small_screw\",\n",
    "    1: \"big_screw\",\n",
    "    2: \"small_wrench\",\n",
    "    3: \"big_wrench\",\n",
    "    4: \"cap\",\n",
    "    5: \"barrel\",\n",
    "    6: \"piston\",\n",
    "    7: \"support\",\n",
    "    8: \"air_connector\",\n",
    "    9: \"nut\"\n",
    "}\n",
    "\n",
    "num_classes_actions = len(Action)\n",
    "num_classes_objects = len(OBJECT_NAMES) + 1 # Last class for empty hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_path = os.path.join(\"assembling_sequence.csv\")\n",
    "base_df = pd.read_csv(base_df_path)\n",
    "\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELETATION_PROBABILITY = 0.05\n",
    "IDLE_REPLACE_PROBABILITY = 0.05\n",
    "IDLE_INSERT_PROBABILITY = 0.05\n",
    "EMPTY_OBJECT_PROBABILITY = 0.05\n",
    "RANDOM_OBJECT_PROBABILITY = 0.05\n",
    "\n",
    "def generate_variation_df(df):\n",
    "    rows = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        deletation_probability = np.random.random()\n",
    "        if deletation_probability > DELETATION_PROBABILITY:\n",
    "            row_dict = row.to_dict()\n",
    "            idle_replace_probability = np.random.random()\n",
    "            if idle_replace_probability < IDLE_REPLACE_PROBABILITY:\n",
    "                row_dict[\"action\"] = 0\n",
    "            object_probability = np.random.random()\n",
    "            if object_probability < EMPTY_OBJECT_PROBABILITY:\n",
    "                row_dict[\"right_hand_object\"] = len(OBJECT_NAMES) if object_probability > RANDOM_OBJECT_PROBABILITY else np.random.randint(len(OBJECT_NAMES) - 1)\n",
    "            rows.append(row_dict)\n",
    "                \n",
    "            idle_insert_probability = np.random.random()\n",
    "            if idle_insert_probability < IDLE_INSERT_PROBABILITY and i < (len(df) - 1):\n",
    "                idle_object = len(OBJECT_NAMES) if idle_insert_probability > RANDOM_OBJECT_PROBABILITY else np.random.randint(len(OBJECT_NAMES) - 1)\n",
    "                idle_row = {\"action\": 0, \"right_hand_object\": idle_object}\n",
    "                rows.append(idle_row)\n",
    "\n",
    "    return pd.DataFrame(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VARIATIONS = 20\n",
    "\n",
    "if not os.path.exists(OBSERVATIONS_FOLDER):\n",
    "    os.makedirs(OBSERVATIONS_FOLDER)\n",
    "\n",
    "print(f\"Saving {NUM_VARIATIONS} variations of base dataframe in folder {OBSERVATIONS_FOLDER}...\")\n",
    "for i in tqdm(range(NUM_VARIATIONS)):\n",
    "    var_df_path = os.path.join(OBSERVATIONS_FOLDER, f\"observation_{i}.csv\")\n",
    "    var_df = generate_variation_df(base_df)\n",
    "    var_df.to_csv(var_df_path, encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dfs = []\n",
    "observation_dfs.append(base_df)\n",
    "for observation_csv in tqdm(os.listdir(OBSERVATIONS_FOLDER)):\n",
    "    observation_df_path = os.path.join(OBSERVATIONS_FOLDER, observation_csv)\n",
    "    observation_dfs.append(pd.read_csv(observation_df_path))\n",
    "\n",
    "concatenated_df = pd.concat(observation_dfs, ignore_index=True)\n",
    "print(\"concatenated_df shape:\", concatenated_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_class(class_index, num_classes):\n",
    "    one_hot_vector = np.zeros(num_classes, dtype=int)\n",
    "    one_hot_vector[class_index] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "def df_to_X_y_data(df, window_size):\n",
    "    df_np = df.to_numpy()\n",
    "    X_data = []\n",
    "    y1_data = []\n",
    "    y2_data = []\n",
    "    for i in range(len(df_np) - window_size):\n",
    "        window_X = []\n",
    "        for row in df_np[i:(i + window_size)]:\n",
    "            window_X.append(np.concatenate((one_hot_encode_class(row[0], num_classes_actions), one_hot_encode_class(row[1], num_classes_objects)), axis=0))\n",
    "            \n",
    "        X_data.append(window_X)\n",
    "        y1_data.append(one_hot_encode_class(df_np[i + window_size][0], num_classes_actions))\n",
    "        y2_data.append(one_hot_encode_class(df_np[i + window_size][1], num_classes_objects))\n",
    "\n",
    "    return np.array(X_data), [np.array(y1_data), np.array(y2_data)]\n",
    "\n",
    "def multi_task_train_val_test_split(X, ys, val_size=0.1, test_size=0.1, shuffle=True, random_state=None):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets for multiple y arrays.\n",
    "    \n",
    "    Parameters:\n",
    "        X: array-like, shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        *ys: array-like, shape (n_samples, )\n",
    "            Multiple target variables.\n",
    "        val_size, test_size: float [0.0, 1.0), default=0.1\n",
    "            Represents the proportion of the dataset to include in the validation and test split respectively.\n",
    "        shuffle: bool, default=True\n",
    "            Whether to shuffle the input dataset.\n",
    "        random_state: int or None, default=None\n",
    "            Controls the randomness of the shuffle.\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test: arrays\n",
    "            Split input data and target variables into train, validation and test sets.\n",
    "    \"\"\"\n",
    "    assert val_size + test_size < 1.0, \"The sum of val_size and test_size must be less than 1.0\"\n",
    "    n_samples = len(X)\n",
    "    for y in ys:\n",
    "        if len(y) != n_samples:\n",
    "            raise ValueError(\"Number of samples in X and y arrays must be the same.\")\n",
    "\n",
    "    if shuffle:\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        X = X[indices]\n",
    "        for i in range(len(ys)):\n",
    "            ys[i] = ys[i][indices]\n",
    "\n",
    "    train_size = 1.0 - val_size - test_size\n",
    "    train_end = int(train_size*n_samples)\n",
    "    val_end = train_end + int(val_size*n_samples)\n",
    "    \n",
    "    X_train = X[:train_end]\n",
    "    y_train = [y[:train_end] for y in ys]\n",
    "    X_val = X[train_end:val_end]\n",
    "    y_val = [y[train_end:val_end] for y in ys]\n",
    "    X_test = X[val_end:]\n",
    "    y_test = [y[val_end:] for y in ys]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = df_to_X_y_data(concatenated_df, window_size=PREDICTION_WINDOW_SIZE)\n",
    "print(\"X shape:\", X_data.shape)\n",
    "print(\"y shape:\", len(y_data), y_data[0].shape, y_data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = multi_task_train_val_test_split(X_data, y_data, val_size=0.1, test_size=0.1, random_state=RANDOM_SEED)\n",
    "print(\"X shape (train, validation, test):\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"y shape (train, validation, test):\", len(y_train), y_train[0].shape, y_train[1].shape, len(y_val), y_val[0].shape, y_val[1].shape, len(y_test), y_test[0].shape, y_test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, X_data, y1_data, y2_data):\n",
    "        self.X_data = X_data\n",
    "        self.y1_data = y1_data\n",
    "        self.y2_data = y2_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    def __getitem__(self, idx):    \n",
    "        return self.X_data[idx], self.y1_data[idx], self.y2_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMMultiTaskClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes1, num_classes2, dropout=0.2):\n",
    "        super(LSTMMultiTaskClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, num_classes1)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc2(out)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "input_size = X_train.shape[2]\n",
    "sequence_length = X_train.shape[1]\n",
    "initial_learning_rate = 0.01\n",
    "num_layers = 3\n",
    "hidden_size = 64\n",
    "\n",
    "model = LSTMMultiTaskClassifier(input_size, hidden_size, num_layers, num_classes_actions, num_classes_objects).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "weight_task1 = 1.0\n",
    "weight_task2 = 0.5\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_learning_rate)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[20, 40], gamma=0.1)\n",
    "\n",
    "summary(model, input_size=(16, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "y1_train_tensor = torch.tensor(y_train[0], dtype=torch.float32).to(device)\n",
    "y1_val_tensor = torch.tensor(y_val[0], dtype=torch.float32).to(device)\n",
    "y1_test_tensor = torch.tensor(y_test[0], dtype=torch.float32).to(device)\n",
    "\n",
    "y2_train_tensor = torch.tensor(y_train[1], dtype=torch.float32).to(device)\n",
    "y2_val_tensor = torch.tensor(y_val[1], dtype=torch.float32).to(device)\n",
    "y2_test_tensor = torch.tensor(y_test[1], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_enabled = True\n",
    "patience = 15\n",
    "min_delta_improvement = 0.001\n",
    "restore_best_weights = False\n",
    "\n",
    "best_loss = np.Inf\n",
    "counter = 0\n",
    "best_epoch = 0\n",
    "\n",
    "if early_stopping_enabled and restore_best_weights:\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_loader = DataLoader(MultiTaskDataset(X_train_tensor, y1_train_tensor, y2_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y1_batch, y2_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y1_batch = y1_batch.to(device)\n",
    "        y2_batch = y2_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs1, outputs2 = model(X_batch)\n",
    "        loss1 = criterion1(outputs1, y1_batch)\n",
    "        loss2 = criterion2(outputs2, y2_batch)\n",
    "        total_loss = weight_task1*loss1 + weight_task2*loss2\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += total_loss.item()\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs1, val_outputs2 = model(X_val_tensor)\n",
    "        val_loss1 = criterion1(val_outputs1, y1_val_tensor)\n",
    "        val_loss2 = criterion2(val_outputs2, y2_val_tensor)\n",
    "        total_val_loss = weight_task1*val_loss1 + weight_task2*val_loss2\n",
    "\n",
    "    train_losses.append(train_loss/len(train_loader))\n",
    "    val_losses.append(total_val_loss.item())\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {total_val_loss:.4f}, lr: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if early_stopping_enabled:\n",
    "        if total_val_loss < best_loss - min_delta_improvement:\n",
    "            best_loss = total_val_loss\n",
    "            counter = 0\n",
    "            best_epoch = epoch + 1\n",
    "            if restore_best_weights:\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter >= patience:\n",
    "            restore_best_weights_message = f\" Best weights restored to epoch {best_epoch}.\" if restore_best_weights else \"\"\n",
    "            print(f\"Early stopping at epoch {epoch + 1} with no improvement in validation loss.{restore_best_weights_message}\")\n",
    "            break\n",
    "\n",
    "# Restore best weights\n",
    "if early_stopping_enabled and restore_best_weights:\n",
    "    model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model state and optimizer state\n",
    "model_checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "torch.save(model_checkpoint, \"model_ap.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model state and optimizer state\n",
    "model_checkpoint = torch.load(\"model_ap.pth\")\n",
    "model.load_state_dict(model_checkpoint[\"state_dict\"])\n",
    "optimizer.load_state_dict(model_checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model TorchScript\n",
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save(os.path.join(\"weights\", \"model_ap.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Total Loss (Weighted Sum of Cross-Entropy Losses)\")\n",
    "plt.legend()\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, normalize=False):\n",
    "    if normalize:\n",
    "        cm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(np.transpose(cm), annot=True, fmt='.2f' if normalize else 'd', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_performance_metrics(y_true, outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, preds)\n",
    "    precision = precision_score(y_true, preds, average=\"macro\")\n",
    "    recall = recall_score(y_true, preds, average=\"macro\")\n",
    "    f1 = f1_score(y_true, preds, average=\"macro\")\n",
    "    conf_matrix = confusion_matrix(y_true, preds)\n",
    "    roc_auc = roc_auc_score(y_true, outputs.cpu().numpy(), multi_class=\"ovr\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    # print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    plot_confusion_matrix(conf_matrix, labels, normalize=True)\n",
    "\n",
    "def ROC_curve(y_true, outputs, labels):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    n_classes = outputs.size(1)\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true == i, outputs[:, i].cpu().numpy())\n",
    "        roc_auc[i] = roc_auc_score(y_true == i, outputs[:, i].cpu().numpy())\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label=f\"ROC curve of action '{labels[i]}' (area = {roc_auc[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower left\", bbox_to_anchor=(0.4, 0.0))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs1, val_outputs2 = model(X_val_tensor)\n",
    "    val_outputs1 = F.softmax(val_outputs1, dim=1)\n",
    "    val_outputs2 = F.softmax(val_outputs2, dim=1)\n",
    "    test_outputs1, test_outputs2 = model(X_test_tensor)\n",
    "    test_outputs1 = F.softmax(test_outputs1, dim=1)\n",
    "    test_outputs2 = F.softmax(test_outputs2, dim=1)\n",
    "\n",
    "val_true1 = torch.argmax(y1_val_tensor, dim=1).cpu().numpy()\n",
    "val_true2 = torch.argmax(y2_val_tensor, dim=1).cpu().numpy()\n",
    "test_true1 = torch.argmax(y1_test_tensor, dim=1).cpu().numpy()\n",
    "test_true2 = torch.argmax(y2_test_tensor, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred1 = torch.argmax(test_outputs1, axis=1).tolist()\n",
    "test_pred2 = torch.argmax(test_outputs2, axis=1).tolist()\n",
    "conf1 = torch.max(test_outputs1, axis=1).values.tolist()\n",
    "conf2 = torch.max(test_outputs2, axis=1).values.tolist()\n",
    "\n",
    "print(\"True - Predicted - Probability\", end=\"\\n\\n\")\n",
    "for i in range(test_outputs1.shape[0]):\n",
    "    true_object_index = test_true2[i]\n",
    "    true_object = OBJECT_NAMES[true_object_index] if true_object_index < len(OBJECT_NAMES) else \"none\"\n",
    "    predicted_object_index = test_pred2[i]\n",
    "    predicted_object = OBJECT_NAMES[predicted_object_index] if predicted_object_index < len(OBJECT_NAMES) else \"none\"\n",
    "\n",
    "    print(f\"{Action(test_true1[i]).name.lower()} {true_object} - {Action(test_pred1[i]).name.lower()} {predicted_object} - {conf1[i]:.3f} {conf2[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set performance metrics - Actions\n",
    "evaluate_performance_metrics(test_true1, test_outputs1, [action.name.lower() for action in list(Action)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set performance metrics - Objects\n",
    "evaluate_performance_metrics(test_true2, test_outputs2, list(OBJECT_NAMES.values()) + [\"none\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set ROC curve - Actions\n",
    "ROC_curve(test_true1, test_outputs1, [action.name.lower() for action in list(Action)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set ROC curve - Objects\n",
    "ROC_curve(test_true2, test_outputs2, list(OBJECT_NAMES.values()) + [\"none\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = np.array((\n",
    "    (1, 7),\n",
    "    (2, 7),\n",
    "    (1, 0),\n",
    "    (2, 0),\n",
    "    (1, 0)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_sequence_data = deque(maxlen=PREDICTION_WINDOW_SIZE)\n",
    "for row in sequence_data:\n",
    "    one_hot_sequence_data.append(np.concatenate((one_hot_encode_class(row[0], num_classes_actions), one_hot_encode_class(row[1], num_classes_objects)), axis=0))\n",
    "\n",
    "model.eval()\n",
    "X = torch.tensor(np.array(one_hot_sequence_data), dtype=torch.float32).to(device)\n",
    "X = torch.unsqueeze(X, axis=0)\n",
    "with torch.no_grad():\n",
    "    outputs1, outputs2 = model(X)\n",
    "    prob1 = F.softmax(outputs1, dim=1)[0]\n",
    "    prob2 = F.softmax(outputs2, dim=1)[0]\n",
    "print(\"Action probabilities:\")\n",
    "for action_index, action_prob in enumerate(prob1):\n",
    "    print(f\"- {Action(action_index).name.lower()}: {(action_prob*100):.2f} %\")\n",
    "action_prediction = Action(torch.argmax(prob1).item()).name.lower()\n",
    "print(\"Action prediction:\", action_prediction, end=\"\\n\\n\")\n",
    "print(\"Object probabilities:\")\n",
    "for object_index, object_prob in enumerate(prob2):\n",
    "    object_name = OBJECT_NAMES[object_index] if object_index < len(OBJECT_NAMES) else \"none\"\n",
    "    print(f\"- {object_name}: {(object_prob*100):.2f} %\")\n",
    "predicted_object_index = torch.argmax(prob2).item()\n",
    "predicted_object = OBJECT_NAMES[predicted_object_index] if predicted_object_index < len(OBJECT_NAMES) else \"none\"\n",
    "print(\"Object prediction:\", predicted_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_action(one_hot_sequence_data):\n",
    "    \"\"\"\n",
    "    Predict the next most probable action based on provided one-hot sequence data.\n",
    "    Returns the probabilities for predicted actions and objects.\n",
    "    \"\"\"\n",
    "    X = torch.tensor(np.array(one_hot_sequence_data), dtype=torch.float32).to(device)\n",
    "    X = torch.unsqueeze(X, axis=0)\n",
    "    with torch.no_grad():\n",
    "        outputs1, outputs2 = model(X)\n",
    "        prob1 = F.softmax(outputs1, dim=1)[0]\n",
    "        prob2 = F.softmax(outputs2, dim=1)[0]\n",
    "        return prob1, prob2\n",
    "\n",
    "def search_for_future_action(sequence_data, action_to_find, force_object=False):\n",
    "    \"\"\"\n",
    "    Uses action prediction to search for a specified future action.\n",
    "    \n",
    "    Parameters:\n",
    "        sequence_data: numpy.ndarray, shape (sequence_length, 2)\n",
    "            Sequence data in pairs (tuple): (action_index, object_index).\n",
    "        action_to_find: Action\n",
    "            Action to search for in the future.\n",
    "        force_object: bool, default False\n",
    "            If True, if the object found for the specified action is none,\n",
    "            the second most probable object will be returned.\n",
    "    \n",
    "    Returns:\n",
    "        prediction_pairs: list\n",
    "            List of predicted pairs from the next step to the action to find.\n",
    "        conf: tuple (action_confidence, object_confidence)\n",
    "            Confidence in the action to be found and the relative predicted object,\n",
    "            calculated as the conditional probability of the prediction_pairs elements (multiplied confidences).\n",
    "        object_forced: bool\n",
    "            Whether the object found for the specified action was forced.\n",
    "            It always returns False if force_object is False.\n",
    "    \"\"\"\n",
    "    one_hot_sequence_data = deque(maxlen=PREDICTION_WINDOW_SIZE)\n",
    "    for action_pair in sequence_data:\n",
    "        one_hot_sequence_data.append(np.concatenate((one_hot_encode_class(action_pair[0], num_classes_actions), one_hot_encode_class(action_pair[1], num_classes_objects)), axis=0))\n",
    "\n",
    "    prediction_pairs = []\n",
    "    confidences = []\n",
    "    object_forced = False\n",
    "    while True:\n",
    "        prob1, prob2 = predict_next_action(one_hot_sequence_data)\n",
    "        action_prediction_index = torch.argmax(prob1).item()\n",
    "        object_prediction_indices = torch.sort(prob2, descending=True).indices.tolist()\n",
    "        \n",
    "        if Action(action_prediction_index) == action_to_find: # Action found\n",
    "            if force_object and object_prediction_indices[0] == len(OBJECT_NAMES): # Object forced\n",
    "                prediction_pairs.append((action_prediction_index, object_prediction_indices[1]))\n",
    "                confidences.append((prob1[action_prediction_index].item(), prob2[object_prediction_indices[1]].item()))\n",
    "                object_forced = True\n",
    "            else: # Object not forced\n",
    "                prediction_pairs.append((action_prediction_index, object_prediction_indices[0]))\n",
    "                confidences.append((prob1[action_prediction_index].item(), prob2[object_prediction_indices[0]].item()))\n",
    "            break\n",
    "        else: # Add predicted row to sequence and predict next\n",
    "            action_pair = (action_prediction_index, object_prediction_indices[0])\n",
    "            prediction_pairs.append(action_pair)\n",
    "            confidences.append((prob1[action_pair[0]].item(), prob2[action_pair[1]].item()))\n",
    "            one_hot_sequence_data.append(np.concatenate((one_hot_encode_class(action_pair[0], num_classes_actions), one_hot_encode_class(action_pair[1], num_classes_objects)), axis=0))\n",
    "\n",
    "    return prediction_pairs, tuple(np.prod(np.array(confidences), axis=0)), object_forced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_pairs, conf, object_forced = search_for_future_action(sequence_data, Action.PICK, force_object=True)\n",
    "print(\"Prediction\", prediction_pairs, conf, object_forced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
