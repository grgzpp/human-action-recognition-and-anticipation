{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "from enum import Enum\n",
    "import winsound\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import serial\n",
    "import serial.tools.list_ports\n",
    "\n",
    "from local_landmark import LocalLandmark\n",
    "from realsense_camera import RealSenseCamera\n",
    "from yolo_object import YoloObject\n",
    "from hand_helper import HandHelper\n",
    "from object_tracker import ObjectTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FPS = 10\n",
    "SAMPLING_SECONDS = 1\n",
    "sequence_length = int(SAMPLING_SECONDS*SAMPLING_FPS)\n",
    "frame_interval = 1.0/SAMPLING_FPS\n",
    "\n",
    "DATA_FOLDER = \"sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 640\n",
    "IMAGE_HEIGHT = 480\n",
    "\n",
    "HAND_CONNECTIONS = ((0, 1), (0, 5), (9, 13), (13, 17), (5, 9), (0, 17), (1, 2), (2, 3), (3, 4), (5, 6), (6, 7), (7, 8),\n",
    "                    (9, 10), (10, 11), (11, 12), (13, 14), (14, 15), (15, 16), (17, 18), (18, 19), (19, 20))\n",
    "\n",
    "OBJECT_NAMES = {\n",
    "    0: \"small_screw\",\n",
    "    1: \"big_screw\",\n",
    "    2: \"small_wrench\",\n",
    "    3: \"big_wrench\",\n",
    "    4: \"cap\",\n",
    "    5: \"barrel\",\n",
    "    6: \"piston\",\n",
    "    7: \"support\",\n",
    "    8: \"air_connector\",\n",
    "    9: \"nut\"\n",
    "}\n",
    "\n",
    "label_colors = [np.random.random(3)*255 for _ in range(len(OBJECT_NAMES))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "yolo_model_path = os.path.join(\"weights\", \"yolov9c_fine_tuned.pt\")\n",
    "yolo_model = YOLO(yolo_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    IDLE = 0\n",
    "    PICK = 1\n",
    "    PLACE = 2\n",
    "    SCREW_WRENCH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_landmarks(frame, model):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame.flags.writeable = False\n",
    "    results = model.process(frame)\n",
    "    return results\n",
    "\n",
    "def extract_hand_landmarks(hand_index, multi_hand_landmarks, multi_handedness, selected_landmarks_indices, extract_depth=False, camera=None):\n",
    "    \"\"\"hand_index: 0 = right, 1 = left\"\"\"\n",
    "    hand_landmarks_list = []\n",
    "    hand_index_in_multi_landmarks = -1\n",
    "    if multi_hand_landmarks and multi_handedness:\n",
    "        for possible_hand_index in range(len(multi_hand_landmarks)):\n",
    "            handedness_classification = multi_handedness[possible_hand_index].classification[0]\n",
    "            handedness_index = handedness_classification.index\n",
    "            handedness_score = handedness_classification.score\n",
    "            if handedness_index == hand_index: # and handedness_score > 0.7\n",
    "                hand_index_in_multi_landmarks = possible_hand_index\n",
    "                break\n",
    "\n",
    "    for i in selected_landmarks_indices:\n",
    "        if hand_index_in_multi_landmarks >= 0:\n",
    "            lm = LocalLandmark.from_mediapipe_hand_landmark(multi_hand_landmarks[hand_index_in_multi_landmarks].landmark[i])\n",
    "            if extract_depth:\n",
    "                lm.set_depth(camera.get_depth(int(lm.x*IMAGE_WIDTH), int(lm.y*IMAGE_HEIGHT)))\n",
    "            hand_landmarks_list.append(lm)\n",
    "        else:\n",
    "            hand_landmarks_list.append(LocalLandmark(0, 0, 0, 0))\n",
    "                \n",
    "    return hand_landmarks_list\n",
    "\n",
    "def draw_landmarks(frame, landmarks, side, connections):\n",
    "    \"\"\"side: 0 = right, 1 = left\"\"\"\n",
    "\n",
    "    if all([lm.is_empty() for lm in landmarks]):\n",
    "        return\n",
    "\n",
    "    left_landmarks_color = (255, 0, 0)\n",
    "    right_landmarks_color = (0, 0, 255)\n",
    "\n",
    "    for lm in landmarks:\n",
    "        if side == 0:\n",
    "            landmarks_color = right_landmarks_color\n",
    "        elif side == 1:\n",
    "            landmarks_color = left_landmarks_color\n",
    "        else:\n",
    "            return\n",
    "        cv2.circle(frame, (int(lm.x*IMAGE_WIDTH), int(lm.y*IMAGE_HEIGHT)), 2, landmarks_color, 2)\n",
    "\n",
    "    for connection in connections:\n",
    "        if connection[1] < len(landmarks):\n",
    "            start_point = (int(landmarks[connection[0]].x*IMAGE_WIDTH), int(landmarks[connection[0]].y*IMAGE_HEIGHT))\n",
    "            end_point = (int(landmarks[connection[1]].x*IMAGE_WIDTH), int(landmarks[connection[1]].y*IMAGE_HEIGHT))\n",
    "            cv2.line(frame, start_point, end_point, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks_from_flattened_array(flattened_landmarks):\n",
    "   N_RIGHT_HAND_LANDMARKS = 21\n",
    "   N_LEFT_HAND_LANDMARKS = 21\n",
    "\n",
    "   right_hand_landmarks = []\n",
    "   left_hand_landmarks = []\n",
    "\n",
    "   cursor = 0\n",
    "   \n",
    "   for _ in range(N_RIGHT_HAND_LANDMARKS):\n",
    "      cursor_end_position = cursor + 4\n",
    "      lm_sub_array = flattened_landmarks[cursor:cursor_end_position]\n",
    "      right_hand_landmarks.append(LocalLandmark.from_np_array(lm_sub_array))\n",
    "      cursor = cursor_end_position\n",
    "\n",
    "   for _ in range(N_LEFT_HAND_LANDMARKS):\n",
    "      cursor_end_position = cursor + 4\n",
    "      lm_sub_array = flattened_landmarks[cursor:cursor_end_position]\n",
    "      left_hand_landmarks.append(LocalLandmark.from_np_array(lm_sub_array))\n",
    "      cursor = cursor_end_position\n",
    "\n",
    "   return right_hand_landmarks, left_hand_landmarks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video_from_sequence_data(data_folder_path):\n",
    "    frame_interval = 1.0/SAMPLING_FPS\n",
    "    \n",
    "    for frame_index in range(sequence_length):\n",
    "        frame_display_time = time.time()\n",
    "        frame = np.zeros(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "        frame_landmarks_data = np.load(os.path.join(data_folder_path, \"landmarks\", f\"frame_{frame_index}.npy\"))\n",
    "        right_hand_landmarks, left_hand_landmarks = get_landmarks_from_flattened_array(frame_landmarks_data)\n",
    "        draw_landmarks(frame, right_hand_landmarks, side=0, connections=HAND_CONNECTIONS)\n",
    "        draw_landmarks(frame, left_hand_landmarks, side=1, connections=HAND_CONNECTIONS)\n",
    "\n",
    "        frame_objects_data = np.load(os.path.join(data_folder_path, \"objects\", f\"frame_{frame_index}.npy\"))\n",
    "        for frame_object_data in frame_objects_data:\n",
    "            label_id, in_hand, x1, y1, x2, y2 = map(int, frame_object_data)\n",
    "            hand_color = (0, 0, 255) if in_hand == 0 else (255, 0, 0)            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), hand_color, 2)\n",
    "            cv2.putText(frame, f\"{OBJECT_NAMES[label_id]}, in_hand: {in_hand}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, hand_color, 1)\n",
    "\n",
    "        cv2.putText(frame, str(frame_index), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Video from data\", frame)\n",
    "\n",
    "        time_taken = time.time() - frame_display_time\n",
    "        time_to_wait = frame_interval - time_taken\n",
    "        if time_to_wait > 0:\n",
    "            time.sleep(time_to_wait)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_acquired_data(data_folder_path, frames_landmarks, frames_objects):\n",
    "    landmarks_folder_path = os.path.join(data_folder_path, \"landmarks\")\n",
    "    objects_folder_path = os.path.join(data_folder_path, \"objects\")\n",
    "\n",
    "    if not os.path.exists(landmarks_folder_path):\n",
    "        os.makedirs(landmarks_folder_path)\n",
    "    if not os.path.exists(objects_folder_path):\n",
    "        os.makedirs(objects_folder_path)\n",
    "\n",
    "    print(f\"Saving sequence data in {data_folder_path}\")\n",
    "    for i in range(len(frames_landmarks)):\n",
    "        file_path = os.path.join(landmarks_folder_path, f\"frame_{i}.npy\")\n",
    "        np.save(file_path, frames_landmarks[i])\n",
    "    for i in range(len(frames_objects)):\n",
    "        file_path = os.path.join(objects_folder_path, f\"frame_{i}.npy\")\n",
    "        np.save(file_path, frames_objects[i])\n",
    "    print(\"Sequence data successfully saved\", end=\"\\n\\n\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    play_video_from_sequence_data(data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arduino_connection_thread(recorder):\n",
    "    ports = serial.tools.list_ports.comports()\n",
    "    for port, desc, _ in ports:\n",
    "        if \"Genuino Uno\" in desc:\n",
    "            com_port = port\n",
    "\n",
    "    conn = serial.Serial(port=com_port, baudrate=9600, timeout=0.1)\n",
    "\n",
    "    while True:\n",
    "        line = conn.readline()\n",
    "        if line == b\"white\\r\\n\":\n",
    "            winsound.Beep(500, 500)\n",
    "            print(f\"Start acquiring data for sequence {recorder.sequence_number} in one second...\")\n",
    "            time.sleep(1)\n",
    "            winsound.Beep(700, 200)\n",
    "            recorder.start_recording()\n",
    "        elif line == b\"red\\r\\n\":\n",
    "            recorder.sequence_number = max(0, recorder.sequence_number - 1)\n",
    "            print(f\"Back to sequence number {recorder.sequence_number}\")\n",
    "        elif line == b\"pedal_low\\r\\n\":\n",
    "            break\n",
    "        \n",
    "    conn.close()\n",
    "    recorder.terminate_recording()\n",
    "    print(\"Stopping acquisition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder:\n",
    "    def __init__(self, action_folder, sequence_number):\n",
    "        self.action_folder = action_folder\n",
    "        self.sequence_number = sequence_number\n",
    "        self.acquiring = False\n",
    "        self.terminate = False\n",
    "        self.first_frame_acquisition_time = 0\n",
    "        self.frame_index = 0\n",
    "        self.frames_landmarks = deque(maxlen=sequence_length)\n",
    "        self.frames_objects = deque(maxlen=sequence_length)\n",
    "    \n",
    "    def start_recording(self):\n",
    "        self.acquiring = True\n",
    "        self.first_frame_acquisition_time = 0\n",
    "        self.frame_index = 0\n",
    "        self.frames_landmarks.clear()\n",
    "        self.frames_objects.clear()\n",
    "\n",
    "    def stop_recording(self):\n",
    "        self.acquiring = False\n",
    "\n",
    "    def terminate_recording(self):\n",
    "        self.terminate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACQUIRE = False\n",
    "ACTION = Action.SCREW_WRENCH.name.lower()\n",
    "\n",
    "if ACQUIRE:\n",
    "    sequence_number = 0\n",
    "    action_folder = os.path.join(DATA_FOLDER, ACTION)\n",
    "    if os.path.exists(action_folder):\n",
    "        sequence_names = os.listdir(action_folder)\n",
    "        if sequence_names:\n",
    "            sequence_numbers = []\n",
    "            for sequence_name in sequence_names:\n",
    "                sequence_numbers.append(int(sequence_name.split('_')[1]))\n",
    "            sequence_number = sorted(sequence_numbers, reverse=True)[0] + 1\n",
    "\n",
    "    recorder = Recorder(action_folder, sequence_number)\n",
    "    threading.Thread(target=arduino_connection_thread, args=(recorder,)).start()\n",
    "\n",
    "camera = RealSenseCamera(image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "camera.connect()\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "hand_helper = HandHelper(image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "object_tracker = ObjectTracker(image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT)\n",
    "\n",
    "try:\n",
    "    with mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while True:\n",
    "            if ACQUIRE and recorder.terminate:\n",
    "                break\n",
    "            ret = camera.acquire_frame()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            color_image = camera.color_image\n",
    "\n",
    "            hands_results = process_landmarks(color_image, hands)\n",
    "            object_results = yolo_model(color_image, verbose=False)[0]\n",
    "\n",
    "            right_hand_landmarks = extract_hand_landmarks(0, hands_results.multi_hand_landmarks, hands_results.multi_handedness, list(range(21)), extract_depth=True, camera=camera)\n",
    "            left_hand_landmarks = extract_hand_landmarks(1, hands_results.multi_hand_landmarks, hands_results.multi_handedness, list(range(21)), extract_depth=True, camera=camera)\n",
    "            hand_helper.register_hands_landmarks(right_hand_landmarks, left_hand_landmarks)\n",
    "            tips_midpoints = hand_helper.get_tips_midpoints()\n",
    "            \n",
    "            seen_yolo_objects = []\n",
    "            for object_result in object_results.boxes:\n",
    "                if object_result.conf.item() > 0.75:\n",
    "                    seen_yolo_objects.append(YoloObject.from_yolo_box_result(object_result))\n",
    "\n",
    "            object_tracker.register_seen_objects(seen_yolo_objects, tips_midpoints)\n",
    "            object_tracker.increment_frame_index()\n",
    "            \n",
    "            if not ACQUIRE:\n",
    "                new_frame_time = time.time()\n",
    "                fps = 1.0/(new_frame_time - prev_frame_time)\n",
    "                prev_frame_time = new_frame_time\n",
    "                cv2.putText(color_image, f\"{fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                draw_landmarks(color_image, right_hand_landmarks, side=0, connections=HAND_CONNECTIONS)\n",
    "                draw_landmarks(color_image, left_hand_landmarks, side=1, connections=HAND_CONNECTIONS)\n",
    "                    \n",
    "                for i, in_hand_tracked_object in enumerate((object_tracker.right_hand_tracked_object, object_tracker.left_hand_tracked_object)):\n",
    "                    if in_hand_tracked_object is None:\n",
    "                        continue\n",
    "                    hand_color = (0, 0, 255) if i == 0 else (255, 0, 0)\n",
    "                    yolo_object = in_hand_tracked_object.yolo_object\n",
    "                    cv2.putText(color_image, f\"{OBJECT_NAMES[yolo_object.label_id]}, visible: {in_hand_tracked_object.is_visible}\", (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, hand_color, 1)\n",
    "                    if in_hand_tracked_object.is_visible:\n",
    "                        cv2.rectangle(color_image, (yolo_object.x1, yolo_object.y1), (yolo_object.x2, yolo_object.y2), hand_color, 2)\n",
    "                        cv2.putText(color_image, f\"id: {in_hand_tracked_object.tracker_id}, {OBJECT_NAMES[yolo_object.label_id]}, conf: {yolo_object.conf:.2f}\",\n",
    "                                    (yolo_object.x1, yolo_object.y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, hand_color, 1)\n",
    "\n",
    "                cv2.imshow(\"RealSense\", color_image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            # Frame data acquisition\n",
    "            if ACQUIRE and recorder.acquiring:\n",
    "                elapsed_time = time.time() - recorder.first_frame_acquisition_time - recorder.frame_index*frame_interval\n",
    "                if not (recorder.first_frame_acquisition_time > 0 and elapsed_time > 2*frame_interval):\n",
    "                    if elapsed_time > frame_interval:\n",
    "                        hands_landmarks = right_hand_landmarks + left_hand_landmarks\n",
    "                        flattened_landmarks = np.concatenate([lm.get_np_array() for lm in hands_landmarks])\n",
    "                        recorder.frames_landmarks.append(flattened_landmarks)\n",
    "                        \n",
    "                        frame_objects = []\n",
    "                        for i, in_hand_tracked_object in enumerate((object_tracker.right_hand_tracked_object, object_tracker.left_hand_tracked_object)):\n",
    "                            if in_hand_tracked_object is None:\n",
    "                                continue\n",
    "                            yolo_object = in_hand_tracked_object.yolo_object\n",
    "                            frame_objects.append(np.array((yolo_object.label_id, i, yolo_object.x1, yolo_object.y1, yolo_object.x2, yolo_object.y2)))\n",
    "                        recorder.frames_objects.append(np.array(frame_objects))\n",
    "                        \n",
    "                        if recorder.frame_index == 0:\n",
    "                            recorder.first_frame_acquisition_time = time.time()\n",
    "                            \n",
    "                        recorder.frame_index += 1\n",
    "                        if recorder.frame_index >= sequence_length:\n",
    "                            data_folder_path = os.path.join(recorder.action_folder, f\"sequence_{recorder.sequence_number}\")\n",
    "                            threading.Thread(target=save_acquired_data, args=(data_folder_path, list(recorder.frames_landmarks), list(recorder.frames_objects))).start()\n",
    "                            recorder.stop_recording()\n",
    "                            recorder.sequence_number += 1\n",
    "                            \n",
    "                else:\n",
    "                    print(\"Video discarted for too many frames skipped\")\n",
    "                    recorder.stop_recording()\n",
    "\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = os.path.join(DATA_FOLDER, Action.PICK.name.lower(), \"sequence_30\") # _mirrored\n",
    "\n",
    "play_video_from_sequence_data(data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
